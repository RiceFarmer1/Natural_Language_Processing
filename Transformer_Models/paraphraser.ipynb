{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import PegasusForConditionalGeneration, PegasusTokenizer\n",
    "from sentence_splitter import SentenceSplitter, split_text_into_sentences\n",
    "\n",
    "model_name = 'tuner007/pegasus_paraphrase' # https://huggingface.co/tuner007/pegasus_paraphrase\n",
    "torch_device = 'cpu'\n",
    "tokenizer = PegasusTokenizer.from_pretrained(model_name)\n",
    "model = PegasusForConditionalGeneration.from_pretrained(model_name).to(torch_device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_response(input_text, num_return_sequences):\n",
    "    batch = tokenizer.prepare_seq2seq_batch([input_text], truncation=True, padding='longest', max_length=100, return_tensors=\"pt\").to(torch_device)\n",
    "    translated = model.generate(**batch, max_length=100, num_beams=10, num_return_sequences=num_return_sequences, temperature=1.5)\n",
    "    tgt_text = tokenizer.batch_decode(translated, skip_special_tokens=True)\n",
    "    return tgt_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Oscar Pang\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\tokenization_utils_base.py:3579: FutureWarning: \n",
      "`prepare_seq2seq_batch` is deprecated and will be removed in version 5 of HuggingFace Transformers. Use the regular\n",
      "`__call__` method to prepare your inputs and the tokenizer under the `as_target_tokenizer` context manager to prepare\n",
      "your targets.\n",
      "\n",
      "Here is a short example:\n",
      "\n",
      "model_inputs = tokenizer(src_texts, ...)\n",
      "with tokenizer.as_target_tokenizer():\n",
      "    labels = tokenizer(tgt_texts, ...)\n",
      "model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
      "\n",
      "See the documentation of your specific tokenizer for more details on the specific arguments to the tokenizer of choice.\n",
      "For a more complete example, see the implementation of `prepare_seq2seq_batch`.\n",
      "\n",
      "  warnings.warn(formatted_warning, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In recent years, the transformer model has become one of the main highlights of advances in deep learning and deep neural networks. Since it was introduced in 2017, the transformer architecture has evolved and branched out into many different variants.\n",
      "\n",
      "The transformer model is one of the highlights of deep learning and deep neural networks. The transformer architecture has evolved since it was introduced.\n"
     ]
    }
   ],
   "source": [
    "# paragraph of text\n",
    "context = input(\"Enter a paragraph\")\n",
    "\n",
    "splitter = SentenceSplitter(language='en')\n",
    "sentence_list = splitter.split(context)\n",
    "\n",
    "# for loop to iterate through the list of sentences and paraphrase each sentence in the iteration\n",
    "paraphrase = []\n",
    "\n",
    "for i in sentence_list:\n",
    "  a = get_response(i, 1)\n",
    "  paraphrase.append(a)\n",
    "\n",
    "# convert back to string\n",
    "paraphrase2 = [' '.join(x) for x in paraphrase]\n",
    "paraphrase3 = [' '.join(x for x in paraphrase2) ]\n",
    "\n",
    "paraphrased_text = str(paraphrase3).strip('[]').strip(\"'\")\n",
    "\n",
    "print(context)\n",
    "print(\"\")\n",
    "print(paraphrased_text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f43cc61ecb9346674920bd0c80871174aab7f47f22ffcff9da1f54708c95c5a8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
